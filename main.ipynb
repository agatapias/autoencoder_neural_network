{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b656e0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data.ipynb\n",
      "importing Jupyter notebook from measure.ipynb\n",
      "importing Jupyter notebook from layer.ipynb\n",
      "importing Jupyter notebook from model.ipynb\n",
      "importing Jupyter notebook from hyperparameter_selection.ipynb\n",
      "importing Jupyter notebook from softmax_layer.ipynb\n",
      "importing Jupyter notebook from classification_model.ipynb\n",
      "importing Jupyter notebook from measurements.ipynb\n",
      "program start\n",
      "x_train.shape: (40000, 784)\n",
      "y_train.shape: (40000,)\n",
      "x_test.shape: (10000, 784)\n",
      "y_train.shape: (10000,)\n",
      "data loading done\n",
      "accuracy: -0.03582009514864921\n",
      "loss: 0.03417774881281053\n",
      "accuracy: -0.02672417201827897\n",
      "loss: 0.023620216800243704\n",
      "accuracy: -0.025284462552293156\n",
      "loss: 0.02325735357504715\n",
      "accuracy: -0.0215609400695865\n",
      "loss: 0.019039191733322993\n",
      "accuracy: -0.022631014497331826\n",
      "loss: 0.020719925937562066\n",
      "accuracy: -0.019199239175482403\n",
      "loss: 0.016849808100606354\n",
      "accuracy: -0.02028582800645907\n",
      "loss: 0.017563219851474132\n",
      "accuracy: -0.019650838973185307\n",
      "loss: 0.01729712257010531\n",
      "accuracy: -0.017111665989244556\n",
      "loss: 0.014902079907390817\n",
      "accuracy: -0.017632935086868466\n",
      "loss: 0.015522710579365528\n",
      "accuracy: -0.015807014088554554\n",
      "loss: 0.013734574887830362\n",
      "accuracy: -0.016135299560269954\n",
      "loss: 0.014129302789270059\n",
      "accuracy: -0.015123242782291931\n",
      "loss: 0.013050816040906231\n",
      "accuracy: -0.015195093369523172\n",
      "loss: 0.013318573742955496\n",
      "accuracy: -0.014430685779502267\n",
      "loss: 0.012406762740356013\n",
      "accuracy: -0.014194724446205917\n",
      "loss: 0.012270995598181653\n",
      "accuracy: -0.013977501993194771\n",
      "loss: 0.012124782348167525\n",
      "accuracy: -0.01363214867771289\n",
      "loss: 0.01168365059025114\n",
      "accuracy: -0.01390692811493726\n",
      "loss: 0.012218934443376715\n",
      "accuracy: -0.01307030238825965\n",
      "loss: 0.011180479282038698\n",
      "accuracy: -0.012917595278862621\n",
      "loss: 0.011044648360321773\n",
      "accuracy: -0.012734278489080488\n",
      "loss: 0.010904308258077785\n",
      "accuracy: -0.01255838368152786\n",
      "loss: 0.010812351753351827\n",
      "accuracy: -0.012727332910397637\n",
      "loss: 0.011037196640712277\n",
      "accuracy: -0.012220620982775076\n",
      "loss: 0.010419385399160047\n",
      "accuracy: -0.01196551808582352\n",
      "loss: 0.010188775334616408\n",
      "accuracy: -0.011805116229381534\n",
      "loss: 0.010038642925482831\n",
      "accuracy: -0.011646398132724705\n",
      "loss: 0.009894620032061445\n",
      "accuracy: -0.01190926494602389\n",
      "loss: 0.010354983523739954\n",
      "accuracy: -0.01148112687596049\n",
      "loss: 0.009733081234376786\n",
      "accuracy: -0.011419578709152944\n",
      "loss: 0.00976582742357782\n",
      "accuracy: -0.011217478362347611\n",
      "loss: 0.009464823672047179\n",
      "accuracy: -0.011370695480917032\n",
      "loss: 0.009783939443466649\n",
      "accuracy: -0.011212307304459998\n",
      "loss: 0.009642513536775997\n",
      "accuracy: -0.011089014551653302\n",
      "loss: 0.009541538111779452\n",
      "accuracy: -0.011121835247910529\n",
      "loss: 0.009532031535559258\n",
      "accuracy: -0.010924319945503663\n",
      "loss: 0.009195900676324885\n",
      "accuracy: -0.010580938474955863\n",
      "loss: 0.00889355477260816\n",
      "accuracy: -0.010489888554932948\n",
      "loss: 0.008812145175948275\n",
      "accuracy: -0.010412142168221089\n",
      "loss: 0.008790350472238374\n",
      "accuracy: -0.010376079436311495\n",
      "loss: 0.008712509572188836\n",
      "accuracy: -0.010459979098824112\n",
      "loss: 0.008938015718734076\n",
      "accuracy: -0.010206288245497274\n",
      "loss: 0.008675562715120941\n",
      "accuracy: -0.010143389714255482\n",
      "loss: 0.008470571025972772\n",
      "accuracy: -0.010013597780230192\n",
      "loss: 0.008377871219591606\n",
      "accuracy: -0.010243911442597491\n",
      "loss: 0.008806539653949183\n",
      "accuracy: -0.010137692639141105\n",
      "loss: 0.008655240268313236\n",
      "accuracy: -0.010209307896635787\n",
      "loss: 0.00875983772065438\n",
      "accuracy: -0.009941054626109766\n",
      "loss: 0.008259540421090209\n",
      "accuracy: -0.009704105120437205\n",
      "loss: 0.008107131776674967\n",
      "accuracy: -0.009817934003726372\n",
      "loss: 0.008395982812799442\n",
      "accuracy: -0.009771978764794763\n",
      "loss: 0.008284458681383366\n",
      "accuracy: -0.010017833041210115\n",
      "loss: 0.008735541914226607\n",
      "accuracy: -0.009534589460368295\n",
      "loss: 0.008041236669497043\n",
      "accuracy: -0.009406557757390882\n",
      "loss: 0.007826383956834448\n",
      "accuracy: -0.009855809199484028\n",
      "loss: 0.008451718663500793\n",
      "accuracy: -0.00952297719484742\n",
      "loss: 0.00810537755897403\n",
      "accuracy: -0.009369516034650999\n",
      "loss: 0.0078014975089893265\n",
      "accuracy: -0.009483324457961718\n",
      "loss: 0.0080578072634986\n",
      "accuracy: -0.009151901868660023\n",
      "loss: 0.007661776392854571\n",
      "accuracy: -0.009324512034470442\n",
      "loss: 0.007775324708092581\n",
      "accuracy: -0.009505248891287546\n",
      "loss: 0.008158585191471623\n",
      "accuracy: -0.009014768026165626\n",
      "loss: 0.007509707339539795\n",
      "accuracy: -0.009319133256490288\n",
      "loss: 0.007916417862773611\n",
      "accuracy: -0.009029930034422111\n",
      "loss: 0.007485761876532432\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import data\n",
    "import measure\n",
    "import layer\n",
    "import model\n",
    "import hyperparameter_selection as hs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import umap\n",
    "import softmax_layer\n",
    "import classification_model\n",
    "import measurements\n",
    "\n",
    "def measure_dimensionality():\n",
    "    dims = [\n",
    "        (258, 144),\n",
    "        (124,64),\n",
    "        (64,32)\n",
    "    ]\n",
    "    \n",
    "    data1 = data.Data()\n",
    "    data1.get_data()\n",
    "    \n",
    "    input_size = 784\n",
    "    epochs = 20\n",
    "    \n",
    "    for dim in dims:\n",
    "        layers = [\n",
    "            layer.Layer(input_size,dim[0],model.relu,model.relu_backward),\n",
    "            layer.Layer(dim[0],dim[1],model.relu,model.relu_backward),\n",
    "            layer.Layer(dim[1],dim[0],model.relu,model.relu_backward),\n",
    "            layer.Layer(dim[0],input_size,model.sigmoid,model.sigmoid_derivative),\n",
    "        ]\n",
    "    \n",
    "        model1 = model.AutoencoderModel(layers,0.01,epochs,50)\n",
    "        model1.train(data1.X_train, data1.y_train, data1.X_val, data1.y_val) #T\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = model1.predict(data1.X_test.T)\n",
    "        test_accuracy = model1.get_accuracy(y_pred,data1.X_test.T)\n",
    "        print(\"test accuracy:\")\n",
    "        print(test_accuracy)\n",
    "\n",
    "        # Show graphs\n",
    "        measure.plot_graph(range(epochs), model1.accuracy_history, \"Accuracy\")\n",
    "        measure.plot_graph(range(epochs), np.array(model1.cost_history).flatten(), \"Loss\")\n",
    "        measure.plot_graph(range(epochs), np.array(model1.cost_history_train).flatten(), \"Train loss\")\n",
    "\n",
    "        plt.imshow(y_pred.T[0].reshape((28,28))*255, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "   \n",
    "def classification_modell():\n",
    "    data1 = data.Data()\n",
    "    data1.get_data()\n",
    "\n",
    "    layers = [\n",
    "        layer.Layer(784,144,model.relu,model.relu_backward),\n",
    "        layer.Layer(144,64,model.relu,model.relu_backward),\n",
    "        layer.Layer(64,144,model.relu,model.relu_backward),\n",
    "        layer.Layer(144,784,model.sigmoid,model.sigmoid_derivative),\n",
    "    ]\n",
    "    \n",
    "    epochs = 20  # 100 is good, but could be better\n",
    "    model1 = model.AutoencoderModel(layers, 0.01, epochs, 100)\n",
    "    model1.train(data1.X_train, data1.X_val) #T\n",
    "    \n",
    "    code = model1.encode(data1.X_train.T).T\n",
    "    code2 = model1.encode(data1.X_val.T).T\n",
    "    code3 = model1.encode(data1.X_test.T).T\n",
    "    \n",
    "    layers = [\n",
    "        layer.Layer(64,124,model.relu,model.relu_backward),\n",
    "        layer.Layer(124,64,model.relu,model.relu_backward),\n",
    "        softmax_layer.SoftmaxLayer(64,10)\n",
    "    ]\n",
    "    \n",
    "    epochs = 100\n",
    "    model2 = classification_model.ClassificationModel(layers, 0.01, epochs, 100)\n",
    "    model2.train(code, data1.y_train, code2, data1.y_val) #T\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model2.predict(code3.T)\n",
    "    test_accuracy = model2.get_accuracy(y_pred,data1.y_test.T)\n",
    "    print(\"test accuracy:\")\n",
    "    print(test_accuracy)\n",
    "    \n",
    "    model1.graph_hidden_layer()\n",
    "    model1.umap_image(data1.X_val.T, data1.y_val)\n",
    "    model1.umap_image(data1.X_test.T, data1.y_test)\n",
    "    \n",
    "    # Show graphs\n",
    "    measure.plot_graph(range(epochs), model2.accuracy_history, \"Accuracy\")\n",
    "    measure.plot_graph(range(epochs), np.array(model2.cost_history).flatten(), \"Loss\")\n",
    "    measure.plot_graph(range(epochs), np.array(model2.cost_history_train).flatten(), \"Train loss\")\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        plt.imshow(y_pred.T[i].reshape((28,28))*255, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def c():\n",
    "    data1 = data.Data()\n",
    "    data1.get_data()\n",
    "    \n",
    "    layers = [\n",
    "        layer.Layer(784,144,model.relu,model.relu_backward),\n",
    "        layer.Layer(144,64,model.relu,model.relu_backward),\n",
    "        softmax_layer.SoftmaxLayer(64,10)\n",
    "    ]\n",
    "    \n",
    "    epochs = 100\n",
    "    model2 = classification_model.ClassificationModel(layers, 0.01, epochs, 100)\n",
    "    model2.train(data1.X_train, data1.y_train, data1.X_val, data1.y_val) #T\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model2.predict(data1.X_test.T)\n",
    "    test_accuracy = model2.get_accuracy(y_pred,data1.y_test.T)\n",
    "    print(\"test accuracy:\")\n",
    "    print(test_accuracy)\n",
    "    \n",
    "    model1.graph_hidden_layer()\n",
    "    model1.umap_image(data1.X_val.T, data1.y_val)\n",
    "    model1.umap_image(data1.X_test.T, data1.y_test)\n",
    "    \n",
    "    # Show graphs\n",
    "    measure.plot_graph(range(epochs), model2.accuracy_history, \"Accuracy\")\n",
    "    measure.plot_graph(range(epochs), np.array(model2.cost_history).flatten(), \"Loss\")\n",
    "    measure.plot_graph(range(epochs), np.array(model2.cost_history_train).flatten(), \"Train loss\")\n",
    "    \n",
    "    plt.imshow(y_pred.T[2].reshape((28,28))*255, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def autoencoder_model():\n",
    "    data1 = data.Data()\n",
    "    data1.get_data()\n",
    "    \n",
    "    input_size = 784\n",
    "    output_size_1 = 144\n",
    "    \n",
    "    layers = [\n",
    "        layer.Layer(input_size,output_size_1,model.relu,model.relu_backward),\n",
    "        layer.Layer(output_size_1,64,model.relu,model.relu_backward),\n",
    "        layer.Layer(64,output_size_1,model.relu,model.relu_backward),\n",
    "        layer.Layer(output_size_1,input_size,model.sigmoid,model.sigmoid_derivative),\n",
    "    ]\n",
    "    \n",
    "    epochs = 20  # 100 is good, but could be better\n",
    "    model1 = model.AutoencoderModel(layers, 0.01, epochs, 10)\n",
    "    model1.train(data1.X_train, data1.X_val) #T\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model1.predict(data1.X_test.T)\n",
    "    test_accuracy = model1.get_accuracy(y_pred,data1.X_test.T)\n",
    "    print(\"test accuracy:\")\n",
    "    print(test_accuracy)\n",
    "    \n",
    "    model1.graph_hidden_layer()\n",
    "    model1.umap_image(data1.X_train.T, data1.y_train)\n",
    "    model1.umap_image(data1.X_val.T, data1.y_val)\n",
    "    model1.umap_image(data1.X_test.T, data1.y_test)\n",
    "    \n",
    "    # Show graphs\n",
    "    measure.plot_graph(range(epochs), model1.accuracy_history, \"Accuracy\")\n",
    "    measure.plot_graph(range(epochs), np.array(model1.cost_history).flatten(), \"Loss\")\n",
    "    measure.plot_graph(range(epochs), np.array(model1.cost_history_train).flatten(), \"Train loss\")\n",
    "    \n",
    "#     plt.imshow(y_pred.T[2].reshape((28,28))*255, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "    # Plot the original test images \n",
    "    print(\"Original test images:\")\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(data1.X_test[i].reshape((28,28))*255, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the decoded \n",
    "    print(\"Decoded images:\")\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(y_pred.T[i].reshape((28,28))*255, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def autoencoder_model_with_l1():\n",
    "    data1 = data.Data()\n",
    "    data1.get_data()\n",
    "    \n",
    "    input_size = 784\n",
    "    output_size_1 = 144\n",
    "    \n",
    "    layers = [\n",
    "        layer.Layer(input_size,output_size_1,model.relu,model.relu_backward),\n",
    "        layer.Layer(output_size_1,64,model.relu,model.relu_backward),\n",
    "        layer.Layer(64,output_size_1,model.relu,model.relu_backward),\n",
    "        layer.Layer(output_size_1,input_size,model.sigmoid,model.sigmoid_derivative),\n",
    "    ]\n",
    "    \n",
    "    epochs = 20  # 100 is good, but could be better\n",
    "    model1 = model.AutoencoderModel(layers, 0.01, epochs, 10, is_l1=True)\n",
    "    model1.train(data1.X_train, data1.X_val) #T\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model1.predict(data1.X_test.T)\n",
    "    test_accuracy = model1.get_accuracy(y_pred,data1.X_test.T)\n",
    "    print(\"test accuracy:\")\n",
    "    print(test_accuracy)\n",
    "    \n",
    "    model1.graph_hidden_layer()\n",
    "    model1.umap_image(data1.X_val.T, data1.y_val)\n",
    "    model1.umap_image(data1.X_test.T, data1.y_test)\n",
    "    \n",
    "    # Show graphs\n",
    "    measure.plot_graph(range(epochs), model1.accuracy_history, \"Accuracy\")\n",
    "    measure.plot_graph(range(epochs), np.array(model1.cost_history).flatten(), \"Loss\")\n",
    "    measure.plot_graph(range(epochs), np.array(model1.cost_history_train).flatten(), \"Train loss\")\n",
    "    \n",
    "    plt.imshow(y_pred.T[2].reshape((28,28))*255, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def autoencoder_model_with_noise():\n",
    "    data1 = data.Data()\n",
    "    data1.get_data()\n",
    "    \n",
    "    input_size = 784\n",
    "    output_size_1 = 144\n",
    "    \n",
    "    layers = [\n",
    "        layer.Layer(input_size,output_size_1,model.relu,model.relu_backward),\n",
    "        layer.Layer(output_size_1,64,model.relu,model.relu_backward),\n",
    "        layer.Layer(64,output_size_1,model.relu,model.relu_backward),\n",
    "        layer.Layer(output_size_1,input_size,model.sigmoid,model.sigmoid_derivative),\n",
    "    ]\n",
    "    \n",
    "    epochs = 20  # 100 is good, but could be better\n",
    "    model1 = model.AutoencoderModel(layers, 0.01, epochs, 10, is_noisy=True)\n",
    "    model1.train(data1.X_train, data1.X_val) #T\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model1.predict(data1.X_test.T)\n",
    "    test_accuracy = model1.get_accuracy(y_pred,data1.X_test.T)\n",
    "    print(\"test accuracy:\")\n",
    "    print(test_accuracy)\n",
    "    \n",
    "    model1.graph_hidden_layer()\n",
    "    model1.umap_image(data1.X_val.T, data1.y_val)\n",
    "    model1.umap_image(data1.X_test.T, data1.y_test)\n",
    "    \n",
    "    # Show graphs\n",
    "    measure.plot_graph(range(epochs), model1.accuracy_history, \"Accuracy\")\n",
    "    measure.plot_graph(range(epochs), np.array(model1.cost_history).flatten(), \"Loss\")\n",
    "    measure.plot_graph(range(epochs), np.array(model1.cost_history_train).flatten(), \"Train loss\")\n",
    "    \n",
    "    plt.imshow(y_pred.T[2].reshape((28,28))*255, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"program start\")\n",
    "    \n",
    "#     autoencoder_model()\n",
    "#     measure_dimensionality()\n",
    "#     classification_modell()\n",
    "#     c()\n",
    "\n",
    "    measurements.measure_dimensionality()\n",
    "    \n",
    "    print(\"program end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab427163",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.measure_batch_size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
